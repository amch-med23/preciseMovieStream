#!/usr/bin/env python3
""" this handles the external API operations """

import requests
import json
import csv
import os
import random

def get_media_ids():
    """ this gets random results from the API."""
    
    omdb_api = "https://www.omdbapi.com/?apikey=5fa754f9"
    omdb_img_api = "https://img.omdbapi.com/?apikey=5fa754f9"
    # the poster_image_api, might not be used since the result on themain api endpoint has 'poster' key
    #ok, i will create list, of imdb lists. movies_lists (5 or 6 for now)
    #then extract ids from these lists, and append them to a nother list, called [available movies id].
    # this last list will contain all the media ids, and this will be used to retreive movies.
    # this approach will consume too many reuests, since we are allowed only 1000 daily limit.(free version).

    imdb_list_1 = 'https://www.imdb.com/list/ls053951083/export'
    imdb_list_2 = 'https://www.imdb.com/list/ls081235533/export'
    imdb_list_3 = 'https://www.imdb.com/list/ls052535080/export'

    available_imdb_lists =[imdb_list_1, imdb_list_2, imdb_list_3]
    csv_data_all = []

    # generating the csv data if the file is not found.
    if not os.path.exists('csv_list_data'):      
        i = 0
        while ( i < len(available_imdb_lists)):
            data = requests.get(available_imdb_lists[i], stream=True).content.decode('utf-8')
            csv_data = csv.reader(data.splitlines(), delimiter=',')
            csv_data_all.append(list(csv_data))
        
            i = i + 1

        #writing the result to a file
        csv_data_json = json.dumps(csv_data_all)
        with open('csv_list_data' , 'w', encoding='utf-8') as f:
            f.write(csv_data_json)
    
    # reading from the csv file
    with open('csv_list_data', 'r') as f:
        file_data = json.load(f)

    final_ids_list = []
    
    #print('we got {} listsof movies.'.format(len(file_data)))
    for k in file_data:
        #print('we have each {}'.format(len(k)))
        for r in k:
            if r[1] != 'Const':
                final_ids_list.append(r[1])

    # i guess no need to save this list (final_ids_list) in a file, we ust gonna work with the csv parsing method.
    # but am doing it to keep data redundent.
    
    if not os.path.exists('imdb_ids'):
        with open('imdb_ids', 'w', encoding='utf-8') as f:
            json_list = json.dumps(final_ids_list)
            f.write(json_list) 
    
    available_media_ids = final_ids_list
    
    return available_media_ids

def media_infos(obj):
    """ gets data about a specific movie by name and year and a plot """
    
    omdb_api = "https://www.omdbapi.com/?apikey=5fa754f9"
    
    title = obj['title'].replace(' ', '+')
    year = str(obj['year'])
    plot = obj['plot']
    final_url = omdb_api + '&t=' + title + '&y=' + year + '&plot=' + plot
    # requesting the resource from the Omdb.
    res = requests.get(final_url)
    cont = res.content
    data = json.loads(cont.decode('utf-8'))

    return data

def recommended_movies(data):
    """ returning a random res of movies """
    

    # the gathered data is already foramtted by the front-end.
    # this data contains a user_name and an email_address of the user requesting the response.
    # we gonna make a request by search to the omdb data base with the elements of key_words, and append each response
    # to a list 'key_words_res_list', and make a request for the liked_movies items and append them to a list 'liked_movies_list'. then make a request
    omdb_api = "https://www.omdbapi.com/?apikey=5fa754f9"
    
    
    qua_user_name = data['user_name']
    qua_user_email = data['user_email']

    keywords_result_list = []
    liked_movies_result_list = []
    
    if data['type'] == 'any':
        """ here am dealing with the type of media the user requested, and this will be present in the calls """
    
        if data['year'] == '':
            """ don't append the no year parameter in the request """
            for i in data['keywords']:
                res_content = requests.get(omdb_api + '&s=' + i).content
                res_data = json.loads(res_content.decode('utf-8'))
                if res_data['Response'] == 'True':
                    keywords_result_list.append(res_data['Search'])
        else:
            """ calls with the year parameter """
            for i in  data['keywords']:
                res_content = requests.get(omdb_api + '&s=' + i + '&y=' + data['year']).content
                res_data = json.loads(res_content.decode('utf-8'))
                if res_data['Response'] == 'True':
                    keywords_result_list.append(res_data['Search'])
        
        # here we make calls to the api using the provided previouselly liked movies
        if data['liked_movies'] == ['']:
            """ dont make calls to liked movies"""
            liked_movies_result_list = []
        else:
            """ make calls to liked movies elements """
            for i in data['liked_movies']:
                res_content = requests.get(omdb_api + '&s=' + i).content
                res_data = json.loads(res_content.decode('utf-8'))
                if res_data['Response'] == 'True':
                    liked_movies_result_list.append(res_data['Search'])

    else:
        """ here we make calls using the '&type=' parameter in the url """
        
        if data['year'] == '':                                                                 
            """ don't append the no year parameter in the request """                          
            for i in data['keywords']:                                                         
                res_content = requests.get(omdb_api + '&s=' + i + '&type=' + data['type']).content
                res_data = json.loads(res_content.decode('utf-8'))
                if res_data['Response'] == 'True':
                    keywords_result_list.append(res_data['Search'])                                          
        else:                                                                                  
            """ calls with the year parameter """                                              
            for i in  data['keywords']:                                                        
                res_content = requests.get(omdb_api + '&s=' + i + '&y=' + data['year'] + '&type=' + data['type']).content
                res_data = json.loads(res_content.decode('utf-8'))
                if res_data['Response'] == 'True':
                    keywords_result_list.append(res_data['Search'])                                          
                                                                                               
        # here we make calls to the api using the provided previouselly liked movies           
        if data['liked_movies'] == ['']:                                                       
            """ dont make calls to liked movies"""                                             
            liked_movies_result_list = []                                                      
        else:                                                                                  
            """ make calls to liked movies elements """                                        
            for i in data['liked_movies']:                                                     
                res_content = requests.get(omdb_api + '&s=' + i).content 
                res_data = json.loads(res_content.decode('utf-8'))
                if res_data['Response'] == 'True': 
                    liked_movies_result_list.append(res_data['Search'])

    # as of now, we have two lists of results 'liked_movies_result_list' and 'keywords_result_list'
    # these two lists contain the results of the calls to omdb api with the provided parameters.

    # now we either send them as an object to the front_end or we process them then we send them.

    # the resulted object here must contains tree keys: 'result', 'probability_rate', 'Response', the probability rate
    # value will be determined using our algorithm. and the Response will be True if all the elements of both lists
    # (kewords_result_list, liked_movies_result_list) have no Error value for 'their own Response key'.

    # the result will be the two generated lists.

    # i thinks we eed to take relevant API keys from the result request, or we can just append them as is (the 2nd option is used for now.)

    #print("this is the keywords_result length {}, and the resut {}".format(len(keywords_result_list), keywords_result_list))
    #print('--------------')
    #print("this is the liked_movies_result length {}, and the resut {}".format(len(liked_movies_result_list), liked_movies_result_list))

    obj_dict = {}
    
    obj_dict['keywords_result'] = keywords_result_list
    obj_dict['liked_movies_result'] = liked_movies_result_list

    return obj_dict




def random_results():
    """gets random results"""

                                                                                                                    
    #i have avoided the use of the csv file directelly(retreiving the random objects from it directely) because of  
    # it's messy foramt and the absense of the Post value(the image url) this would have saved us API calls and will
    # help with the limit. but still we have scrapped 2182 ids, we are gonna select random 10 from them each time we
    # receive a request.                                                                                            

    omdb_api = "https://www.omdbapi.com/?apikey=5fa754f9"

    movies_ids = get_media_ids()
    random_movies_ids = random.choices(movies_ids, k=10) # getting random 10 elements.

    movies_obj_list = []
    for i in random_movies_ids:
        final_url = omdb_api + '&i=' + str(i)
        cont = requests.get(final_url).content
        movies_obj_list.append(json.loads(cont.decode('utf-8')))
    
    # now we take only the Poster (image), and the title of each element in the movies_obj_list and return we return them.
    final_random_movies_list = []
    
    k = 0
    while k < len(movies_obj_list):
        obj = {}
        for key, value in movies_obj_list[k].items():
            if key =="Title" or key == "Poster" or key == "Year":
                obj[key] = value
        final_random_movies_list.append(obj)        
        k = k + 1

    return final_random_movies_list

def movies_imdb_ids():
    """ getting the nmber of mvies available from the local pool. """
    # reading the imdb_ids file.
    with open('imdb_ids', 'r') as f:
        json_data = json.load(f) # here just load the json data from the file, don't read the file then load the data from the object you read.


    media_ids_number =len(json_data)

    return media_ids_number
    
if __name__ == "__main__":
    """ invoking the script directelly """
    print("invoking...")
    
